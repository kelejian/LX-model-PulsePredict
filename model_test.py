# flake8: noqa
import torch
import torch.nn as nn
import torch.onnx
from torchinfo import summary
from torchviz import make_dot

# @profile
def test_model(
    model,
    inputs,
    labels,
    criterion=None,
    optimizer=None,
    onnx_file_path="model_test.onnx"
):
    """
    é€šç”¨åŒ–æ¨¡å‹æµ‹è¯•å‡½æ•°ï¼š
    1. æ¥å—ä»»æ„æ¨¡å‹å®ä¾‹åŒ–å¯¹è±¡ `model`ã€‚
    2. è‡ªå®šä¹‰è¾“å…¥ `inputs` å’Œæ ‡ç­¾ `labels`ã€‚
    3. æ”¯æŒå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€‚
    4. å¯¼å‡º ONNX æ¨¡å‹å¹¶éªŒè¯ã€‚
    5. è¾“å‡ºæ¨¡å‹è¯¦ç»†ä¿¡æ¯ã€‚
    
    å‚æ•°ï¼š
    - model: PyTorch æ¨¡å‹å®ä¾‹åŒ–å¯¹è±¡: torch.nn.Module
    - inputs: æ¨¡å‹çš„è¾“å…¥å¼ é‡: tensor æˆ– tulple(tensor1, tensor2, ...) æˆ– list(tensor1, tensor2, ...)
    - labels: æ¨¡å‹çš„çœŸå®æ ‡ç­¾å¼ é‡ï¼ˆç”¨äºæŸå¤±è®¡ç®—ï¼‰: tensor
    - criterion: æŸå¤±å‡½æ•°å®ä¾‹åŒ–å¯¹è±¡ï¼Œé»˜è®¤ä¸º nn.MSELoss
    - optimizer: ä¼˜åŒ–å™¨å®ä¾‹åŒ–å¯¹è±¡ï¼Œé»˜è®¤ä¸º Adam
    - onnx_file_path: å¯¼å‡ºçš„ ONNX æ–‡ä»¶è·¯å¾„
    """
    # é»˜è®¤æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    if criterion is None:
        criterion = nn.MSELoss()
    if optimizer is None:
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # å°†æ¨¡å‹è®¾ä¸ºè®­ç»ƒæ¨¡å¼
    model.train()
    print("\n~~~~~~~~~~~~~~~~~~~ ğŸš€ğŸš€ å¼€å§‹æµ‹è¯•ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸è®­ç»ƒ ğŸš€ğŸš€ ~~~~~~~~~~~~~~~~~~~~")
    # æ‰“å°æ¨¡å‹ç»“æ„ä¿¡æ¯
    print("\n============== æ¨¡å‹ç»“æ„ä¿¡æ¯ ==============")
    _input_data = tuple(inputs) if isinstance(inputs, (tuple, list)) else inputs
    
    try:
        summary(
            model,
            input_data=_input_data,
            col_names=["input_size", "output_size", "num_params"],
            depth=3,
            device="cuda" if next(model.parameters()).is_cuda else "cpu"
        )
    except Exception as e:
        print(f"âš  torchinfo.summary æ‰§è¡Œå¤±è´¥: {e}")
        print("ç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # å‰å‘ä¼ æ’­ä¸lossè®¡ç®—
    print("\n============== å‰å‘ä¼ æ’­ ==============")
    if isinstance(inputs, (tuple, list)):
        outputs = model(*inputs)
        # ä¸€è¡Œæ‰“å°æ¨¡å‹å„ä¸ªè¾“å…¥inputçš„å½¢çŠ¶
        print(f"âœ” æ¨¡å‹å„ä¸ªè¾“å…¥çš„å½¢çŠ¶ï¼š{[input.shape for input in inputs]}")

    else:
        outputs = model(inputs)
        print(f"âœ” è¾“å…¥å½¢çŠ¶ï¼š{inputs.shape}")

    # æ£€æŸ¥ outputs æ˜¯å¦ä¸º tuple æˆ– list,ä½†æ’é™¤ torch.Tensor
    if isinstance(outputs, (tuple, list)) and not isinstance(outputs, torch.Tensor):
        # ä¸€è¡Œæ‰“å°æ¨¡å‹å„ä¸ªè¾“å‡ºoutputçš„å½¢çŠ¶
        try:
            output_info = []
            for output in outputs:
                if isinstance(output, torch.Tensor):
                    output_info.append(f"Tensor{tuple(output.shape)}")
                elif isinstance(output, (tuple, list)):
                    # å¤„ç†åµŒå¥—çš„ tuple/list (å¦‚ GaussianNLL è¾“å‡º)
                    sub_info = []
                    for sub_output in output:
                        if isinstance(sub_output, torch.Tensor):
                            sub_info.append(f"Tensor{tuple(sub_output.shape)}")
                        else:
                            sub_info.append(str(type(sub_output)))
                    output_info.append(f"({', '.join(sub_info)})")
                else:
                    output_info.append(str(type(output)))
            print(f"âœ” æ¨¡å‹è¾“å‡ºç»“æ„ï¼š[{', '.join(output_info)}]")
        except Exception as e:
            print(f"âœ” æ¨¡å‹è¾“å‡ºç±»å‹ï¼š{type(outputs)}, åŒ…å« {len(outputs)} ä¸ªå…ƒç´ ")
            print(f"âœ” å„å…ƒç´ ç±»å‹ï¼š{[type(output) for output in outputs]}")
        
        # å°è¯•ä»å¤šå°ºåº¦è¾“å‡ºä¸­æ‰¾åˆ°åŒ¹é…çš„è¾“å‡ºè¿›è¡Œ loss è®¡ç®—
        loss = None
        matched_output = None
        
        for i, output in enumerate(outputs):
            # å¤„ç† (mean, var) å…ƒç»„æ ¼å¼
            if isinstance(output, (tuple, list)) and len(output) >= 1:
                current_output = output[0] if isinstance(output[0], torch.Tensor) else output
            else:
                current_output = output
            
            if isinstance(current_output, torch.Tensor):
                # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
                if current_output.shape == labels.shape:
                    loss = criterion(current_output, labels)
                    matched_output = current_output
                    print(f"âœ” ä½¿ç”¨ç¬¬ {i+1} ä¸ªè¾“å‡ºï¼ˆå½¢çŠ¶: {tuple(current_output.shape)}ï¼‰è®¡ç®—æŸå¤±: {loss.item():.6f}")
                    break
        
        if loss is None:
            # å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…çš„ï¼Œå°è¯•ä½¿ç”¨æœ€åä¸€ä¸ªè¾“å‡º
            print("âš  æ‰€æœ‰è¾“å‡ºå½¢çŠ¶ä¸æ ‡ç­¾ä¸å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªè¾“å‡º...")
            last_output = outputs[-1]
            if isinstance(last_output, (tuple, list)):
                last_output = last_output[0] if isinstance(last_output[0], torch.Tensor) else last_output
            
            if isinstance(last_output, torch.Tensor):
                # å°è¯•å¯¹é½æ ‡ç­¾å½¢çŠ¶
                if last_output.shape[-1] != labels.shape[-1]:
                    print(f"  è°ƒæ•´æ ‡ç­¾å½¢çŠ¶: {tuple(labels.shape)} -> æ’å€¼åˆ°é•¿åº¦ {last_output.shape[-1]}")
                    aligned_labels = torch.nn.functional.interpolate(
                        labels, 
                        size=last_output.shape[-1], 
                        mode='linear', 
                        align_corners=False
                    )
                else:
                    aligned_labels = labels
                
                loss = criterion(last_output, aligned_labels)
                matched_output = last_output
                print(f"âœ” ä½¿ç”¨æœ€åä¸€ä¸ªè¾“å‡ºï¼ˆå½¢çŠ¶: {tuple(last_output.shape)}ï¼‰è®¡ç®—æŸå¤±: {loss.item():.6f}")
            else:
                raise ValueError(f"æ— æ³•ä»è¾“å‡ºä¸­æå–æœ‰æ•ˆçš„å¼ é‡è¿›è¡ŒæŸå¤±è®¡ç®—ï¼Œæœ€åè¾“å‡ºç±»å‹: {type(last_output)}")

    else:
        print(f"âœ” æ¨¡å‹è¾“å‡ºå½¢çŠ¶ï¼š{outputs.shape}")
        if labels.shape == outputs.shape:
            loss = criterion(outputs, labels)
            matched_output = outputs
            print(f"âœ” æŸå¤±å€¼ï¼š{loss.item():.6f}")
        else: 
            print(f"âš  æ¨¡å‹è¾“å‡ºå½¢çŠ¶ {tuple(outputs.shape)} ä¸æ ‡ç­¾å½¢çŠ¶ {tuple(labels.shape)} ä¸åŒ¹é…")
            # å°è¯•è°ƒæ•´å½¢çŠ¶åè®¡ç®—æŸå¤±
            try:
                if outputs.shape[-1] != labels.shape[-1]:
                    aligned_labels = torch.nn.functional.interpolate(
                        labels, 
                        size=outputs.shape[-1], 
                        mode='linear', 
                        align_corners=False
                    )
                    loss = criterion(outputs, aligned_labels)
                    matched_output = outputs
                    print(f"âœ” è°ƒæ•´æ ‡ç­¾å½¢çŠ¶åè®¡ç®—æŸå¤±å€¼ï¼š{loss.item():.6f}")
                else:
                    loss = criterion(outputs.view_as(labels), labels)
                    matched_output = outputs
                    print(f"âœ” è°ƒæ•´è¾“å‡ºå½¢çŠ¶åè®¡ç®—æŸå¤±å€¼ï¼š{loss.item():.6f}")
            except Exception as e:
                print(f"âœ˜ æ— æ³•é€šè¿‡è°ƒæ•´å½¢çŠ¶è®¡ç®—æŸå¤±: {e}")
                loss = criterion(outputs, labels)  # å¼ºåˆ¶è®¡ç®—ä»¥ä¾¿åç»­åå‘ä¼ æ’­æµ‹è¯•
                matched_output = outputs


    # åå‘ä¼ æ’­
    print("\n============== åå‘ä¼ æ’­ ==============")
    try:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print("âœ” åå‘ä¼ æ’­æ­£å¸¸~")
    except Exception as e:
        print(f"âœ˜ åå‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    # å¯è§†åŒ–è®¡ç®—å›¾
    print("\n============== è®¡ç®—å›¾å¯è§†åŒ– ==============")
    try:
        graph = make_dot(loss, params=dict(model.named_parameters()))
        graph.render("model_computation_graph", format="png")
        print("âœ” è®¡ç®—å›¾å·²ä¿å­˜ä¸º 'model_computation_graph.png'")
    except Exception as e:
        print(f"âš  è®¡ç®—å›¾å¯è§†åŒ–å¤±è´¥: {e}")

    # å¯¼å‡º ONNX æ¨¡å‹
    print("\n============== å¯¼å‡º ONNX æ¨¡å‹ ==============")
    
    try:
        # æ ¹æ®è¾“å…¥ç±»å‹é…ç½®è¾“å…¥åç§°å’ŒåŠ¨æ€è½´
        if isinstance(inputs, (tuple, list)):
            input_names = [f"input_{i}" for i in range(len(inputs))]
            dynamic_axes = {f"input_{i}": {0: "batch_size"} for i in range(len(inputs))}
        else:
            input_names = ["input"]
            dynamic_axes = {"input": {0: "batch_size"}}
        
        # é…ç½®è¾“å‡ºåç§°å’ŒåŠ¨æ€è½´ï¼ˆå¤„ç†å¤šå°ºåº¦å’ŒåµŒå¥—ç»“æ„ï¼‰
        output_names = []
        output_idx = 0
        
        if isinstance(outputs, (tuple, list)) and not isinstance(outputs, torch.Tensor):
            for stage_output in outputs:
                if isinstance(stage_output, (tuple, list)):
                    for sub_output in stage_output:
                        if isinstance(sub_output, torch.Tensor):
                            output_names.append(f"output_{output_idx}")
                            dynamic_axes[f"output_{output_idx}"] = {0: "batch_size"}
                            output_idx += 1
                elif isinstance(stage_output, torch.Tensor):
                    output_names.append(f"output_{output_idx}")
                    dynamic_axes[f"output_{output_idx}"] = {0: "batch_size"}
                    output_idx += 1
        else:
            output_names = ["output"]
            dynamic_axes["output"] = {0: "batch_size"}
        
        torch.onnx.export(
            model,
            _input_data,
            onnx_file_path,
            input_names=input_names,
            output_names=output_names,
            dynamic_axes=dynamic_axes,
            opset_version=11,
        )
        print(f"âœ” ONNX æ¨¡å‹å·²ä¿å­˜è‡³ {onnx_file_path}")
        print("  åœ¨ https://netron.app/ ä¸ŠæŸ¥çœ‹ ONNX æ¨¡å‹ç»“æ„")
    except Exception as e:
        print(f"âš  ONNX å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    from utils import read_json
    from parse_config import ConfigParser
    import model.model as module_arch

    # æ¨¡å‹å®ä¾‹åŒ–
    config = ConfigParser(read_json('config.json'))
    Pulsemodel = config.init_obj('arch', module_arch)
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°CUDAè®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    Pulsemodel = Pulsemodel.to(device)

    # ç¤ºä¾‹è¾“å…¥æ•°æ®ï¼ˆæ ¹æ®æ¨¡å‹å®é™…è¾“å…¥ç»´åº¦ï¼‰
    batch_size = 128

    # ä¿®æ­£ï¼šæ¨¡å‹è¾“å…¥åº”ä¸º (B, input_dim)ï¼Œé»˜è®¤ input_dim=3
    x = torch.randn(batch_size, 3).to(device)  # å·¥å†µç‰¹å¾è¾“å…¥
    
    # æ ‡ç­¾æ•°æ®ï¼ˆç›®æ ‡åŠ é€Ÿåº¦æ³¢å½¢ï¼‰
    y = torch.randn(batch_size, 3, 150).to(device)  # (B, C, L) ä¸‰è½´åŠ é€Ÿåº¦

    print(f"\n{'='*80}")
    print(f"æ¨¡å‹ç±»å‹: {type(Pulsemodel).__name__}")
    print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {x.shape}")
    print(f"æ ‡ç­¾æ•°æ®å½¢çŠ¶: {y.shape}")
    print(f"è®¡ç®—è®¾å¤‡: {device}")
    print(f"{'='*80}")

    # æµ‹è¯•æ¨¡å‹
    test_model(Pulsemodel, inputs=x, labels=y)
