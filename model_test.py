# flake8: noqa
import torch
import torch.nn as nn
import torch.onnx
from torchinfo import summary
from torchviz import make_dot

# @profile
def test_model(
    model,
    inputs,
    labels,
    criterion=None,
    optimizer=None,
    onnx_file_path="model_test.onnx"
):
    """
    é€šç”¨åŒ–æ¨¡å‹æµ‹è¯•å‡½æ•°ï¼š
    1. æ¥å—ä»»æ„æ¨¡å‹å®ä¾‹åŒ–å¯¹è±¡ `model`ã€‚
    2. è‡ªå®šä¹‰è¾“å…¥ `inputs` å’Œæ ‡ç­¾ `labels`ã€‚
    3. æ”¯æŒå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€‚
    4. å¯¼å‡º ONNX æ¨¡å‹å¹¶éªŒè¯ã€‚
    5. è¾“å‡ºæ¨¡å‹è¯¦ç»†ä¿¡æ¯ã€‚
    
    å‚æ•°ï¼š
    - model: PyTorch æ¨¡å‹å®ä¾‹åŒ–å¯¹è±¡: torch.nn.Module
    - inputs: æ¨¡å‹çš„è¾“å…¥å¼ é‡: tensor æˆ– tulple(tensor1, tensor2, ...) æˆ– list(tensor1, tensor2, ...)
    - labels: æ¨¡å‹çš„çœŸå®æ ‡ç­¾å¼ é‡ï¼ˆç”¨äºæŸå¤±è®¡ç®—ï¼‰: tensor
    - criterion: æŸå¤±å‡½æ•°å®ä¾‹åŒ–å¯¹è±¡ï¼Œé»˜è®¤ä¸º nn.MSELoss
    - optimizer: ä¼˜åŒ–å™¨å®ä¾‹åŒ–å¯¹è±¡ï¼Œé»˜è®¤ä¸º Adam
    - onnx_file_path: å¯¼å‡ºçš„ ONNX æ–‡ä»¶è·¯å¾„
    """
    # é»˜è®¤æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    if criterion is None:
        criterion = nn.MSELoss()
    if optimizer is None:
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # å°†æ¨¡å‹è®¾ä¸ºè®­ç»ƒæ¨¡å¼
    model.train()
    print("\n~~~~~~~~~~~~~~~~~~~ ğŸš€ğŸš€ å¼€å§‹æµ‹è¯•ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸è®­ç»ƒ ğŸš€ğŸš€ ~~~~~~~~~~~~~~~~~~~~")
    # æ‰“å°æ¨¡å‹ç»“æ„ä¿¡æ¯
    print("\n============== æ¨¡å‹ç»“æ„ä¿¡æ¯ ==============")
    _input_data = tuple(inputs) if isinstance(inputs, (tuple, list)) else inputs
    summary(
        model,
        input_data=_input_data,
        col_names=["input_size", "output_size", "num_params"],
        depth=3,
        device="cuda" if next(model.parameters()).is_cuda else "cpu"
    )
    
    # å‰å‘ä¼ æ’­ä¸lossè®¡ç®—
    print("\n============== å‰å‘ä¼ æ’­ ==============")
    if isinstance(inputs, (tuple, list)):
        outputs = model(*inputs)
        # ä¸€è¡Œæ‰“å°æ¨¡å‹å„ä¸ªè¾“å…¥inputçš„å½¢çŠ¶
        print(f"âœ” æ¨¡å‹å„ä¸ªè¾“å…¥çš„å½¢çŠ¶ï¼š{[input.shape for input in inputs]}")

    else:
        outputs = model(inputs)
        print(f"âœ” è¾“å…¥å½¢çŠ¶ï¼š{inputs.shape}")

    # æ£€æŸ¥ outputs æ˜¯å¦ä¸º tuple æˆ– list,ä½†æ’é™¤ torch.Tensor
    if isinstance(outputs, (tuple, list)) and not isinstance(outputs, torch.Tensor):
        # ä¸€è¡Œæ‰“å°æ¨¡å‹å„ä¸ªè¾“å‡ºoutputçš„å½¢çŠ¶
        try:
            print(f"âœ” æ¨¡å‹å„ä¸ªè¾“å‡ºçš„å½¢çŠ¶ï¼š{[output.shape if isinstance(output, torch.Tensor) else type(output) for output in outputs]}")
        except Exception as e:
            print(f"âœ” æ¨¡å‹è¾“å‡ºç±»å‹ï¼š{type(outputs)}, åŒ…å« {len(outputs)} ä¸ªå…ƒç´ ")
            print(f"âœ” å„å…ƒç´ ç±»å‹ï¼š{[type(output) for output in outputs]}")
        
        loss = None
        for i, output in enumerate(outputs):
            if isinstance(output, torch.Tensor) and labels.shape == output.shape:
                loss = criterion(output, labels)
                print(f"âœ” ç¬¬{i+1}ä¸ªæ¨¡å‹è¾“å‡ºå¯¹åº”äº†ä¸€ä¸ªlosså€¼: {loss.item()}")
        
        if loss is None:
            print("âœ˜ æ‰€æœ‰æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸æ ‡ç­¾å½¢çŠ¶éƒ½ä¸åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å‡ºè®¡ç®—æŸå¤±")
            first_tensor = outputs[0] if isinstance(outputs[0], torch.Tensor) else outputs[0][0]
            loss = criterion(first_tensor, labels)
            print(f"âœ” æŸå¤±å€¼ï¼š{loss.item()}")

    else:
        print(f"âœ” æ¨¡å‹è¾“å‡ºå½¢çŠ¶ï¼š{outputs.shape}")
        if labels.shape == outputs.shape:
            loss = criterion(outputs, labels)
            print(f"âœ” æŸå¤±å€¼ï¼š{loss.item()}")
        else: 
            print("âœ˜ æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸æ ‡ç­¾å½¢çŠ¶ä¸åŒ¹é…ï¼Œæ— æ³•è®¡ç®—æŸå¤±å€¼")
            # å°è¯•è°ƒæ•´å½¢çŠ¶åè®¡ç®—æŸå¤±
            try:
                loss = criterion(outputs.view_as(labels), labels)
                print(f"âœ” è°ƒæ•´å½¢çŠ¶åè®¡ç®—æŸå¤±å€¼ï¼š{loss.item()}")
            except:
                print("âœ˜ æ— æ³•é€šè¿‡è°ƒæ•´å½¢çŠ¶è®¡ç®—æŸå¤±ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºå’Œæ ‡ç­¾çš„ç»´åº¦")
                loss = criterion(outputs, labels)  # å¼ºåˆ¶è®¡ç®—ä»¥ä¾¿åç»­åå‘ä¼ æ’­æµ‹è¯•


    # åå‘ä¼ æ’­
    print("\n============== åå‘ä¼ æ’­ ==============")
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    print("âœ” åå‘ä¼ æ’­æ­£å¸¸~")

    # å¯è§†åŒ–è®¡ç®—å›¾
    print("\n============== è®¡ç®—å›¾å¯è§†åŒ– ==============")
    graph = make_dot(loss, params=dict(model.named_parameters()))
    graph.render("model_computation_graph", format="png")
    print("âœ” è®¡ç®—å›¾å·²ä¿å­˜ä¸º 'model_computation_graph.png'")

    # å¯¼å‡º ONNX æ¨¡å‹
    print("\n============== å¯¼å‡º ONNX æ¨¡å‹ ==============")
    
    # æ ¹æ®è¾“å…¥ç±»å‹é…ç½®è¾“å…¥åç§°å’ŒåŠ¨æ€è½´
    if isinstance(inputs, (tuple, list)):
        input_names = [f"input_{i}" for i in range(len(inputs))]
        dynamic_axes = {f"input_{i}": {0: "batch_size"} for i in range(len(inputs))}
    else:
        input_names = ["input"]
        dynamic_axes = {"input": {0: "batch_size"}}
    
    # é…ç½®è¾“å‡ºåç§°å’ŒåŠ¨æ€è½´
    if isinstance(outputs, (tuple, list)) and not isinstance(outputs, torch.Tensor):
        output_names = [f"output_{i}" for i in range(len(outputs))]
        for i in range(len(outputs)):
            dynamic_axes[f"output_{i}"] = {0: "batch_size"}
    else:
        output_names = ["output"]
        dynamic_axes["output"] = {0: "batch_size"}
    
    torch.onnx.export(
        model,
        _input_data,
        onnx_file_path,
        input_names=input_names,
        output_names=output_names,
        dynamic_axes=dynamic_axes,
        opset_version=11,
    )
    print(f"âœ” ONNX æ¨¡å‹å·²ä¿å­˜è‡³ {onnx_file_path}")
    print("åœ¨ https://netron.app/ ä¸ŠæŸ¥çœ‹ ONNX æ¨¡å‹ç»“æ„")

    # # ä½¿ç”¨ ONNX Runtime æ¨ç†
    # print("\n============== ONNX Runtime æ¨ç† ==============")
    # ort_session = onnxruntime.InferenceSession(onnx_file_path)
    # ort_inputs = {
    #     onnx_model.graph.input[i].name: (
    #         inputs[i].cpu().numpy() if isinstance(inputs, (tuple, list))
    #         else inputs.cpu().numpy()
    #     )
    #     for i in range(len(onnx_model.graph.input))
    # }
    # ort_outs = ort_session.run(None, ort_inputs)
    # print(f"ONNX æ¨ç†è¾“å‡ºï¼š{ort_outs}")

if __name__ == "__main__":
    from utils import read_json
    from parse_config import ConfigParser
    import model.model as module_arch

    # æ¨¡å‹å®ä¾‹åŒ–
    config = ConfigParser(read_json('config_CNN.json'))
    Pulsemodel = config.init_obj('arch', module_arch)
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°CUDAè®¾å¤‡
    Pulsemodel = Pulsemodel.cuda()

    # ç¤ºä¾‹è¾“å…¥æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ•°æ®é›†ç¬¬1ä¸ªbatchï¼‰
    batch_size = 128

    y = torch.randn(batch_size, 3, 150).cuda()
    x = torch.randn(batch_size, 3).cuda()  # éšæœºç”Ÿæˆè¿ç»­ç‰¹å¾

    # æµ‹è¯•æ¨¡å‹
    test_model(Pulsemodel, inputs=x, labels=y)
